{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22229,
     "status": "ok",
     "timestamp": 1724484024821,
     "user": {
      "displayName": "Saeed Ahmed",
      "userId": "16724720564507897686"
     },
     "user_tz": -120
    },
    "id": "WRf5CIJEf48l",
    "outputId": "44d950e4-f538-4e7f-b0c3-07ad74c8cb29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14075,
     "status": "ok",
     "timestamp": 1724170758102,
     "user": {
      "displayName": "Saeed Ahmed",
      "userId": "16724720564507897686"
     },
     "user_tz": -120
    },
    "id": "iuFk0TzMj1hW",
    "outputId": "c8376699-8750-4953-f121-5584a1579859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Installing collected packages: imblearn\n",
      "Successfully installed imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7176,
     "status": "ok",
     "timestamp": 1724484031994,
     "user": {
      "displayName": "Saeed Ahmed",
      "userId": "16724720564507897686"
     },
     "user_tz": -120
    },
    "id": "Tym3f4FvVsbI"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    '''Convert class vector (integers from 0 to nb_classes)\n",
    "    to binary class matrix, for use with categorical_crossentropy.\n",
    "    '''\n",
    "    y = np.array(y, dtype='int')\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y) + 1\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "    for i in range(len(y)):\n",
    "        Y[i, y[i]] = 1.\n",
    "    return Y\n",
    "\n",
    "def calculate_performance(test_num, pred_y, labels, pred_probas=None):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index in range(test_num):\n",
    "        if labels[index] == 1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp = tp + 1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "\n",
    "    acc = float(tp + tn) / test_num\n",
    "    precision = float(tp) / (tp + fp + 1e-06)\n",
    "    npv = float(tn) / (tn + fn + 1e-06)\n",
    "    sensitivity = float(tp) / (tp + fn + 1e-06)\n",
    "    specificity = float(tn) / (tn + fp + 1e-06)\n",
    "    mcc = float(tp * tn - fp * fn) / (math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) + 1e-06)\n",
    "    f1 = float(tp * 2) / (tp * 2 + fp + fn + 1e-06)\n",
    "    # Calculate FPR and TPR\n",
    "    fpr = fp / (fp + tn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    # Calculate AUPR\n",
    "    aupr = None\n",
    "    if pred_probas is not None:\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(labels, pred_probas)\n",
    "        aupr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # roc_auc = auc(fpr, tpr)\n",
    "    return acc, sensitivity, specificity, mcc, f1, aupr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG2FDU72_cqp"
   },
   "source": [
    "**Load input data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4161,
     "status": "ok",
     "timestamp": 1724492063600,
     "user": {
      "displayName": "Saeed Ahmed",
      "userId": "16724720564507897686"
     },
     "user_tz": -120
    },
    "id": "0QQDV3TR_bvW",
    "outputId": "367bc91f-95e0-407f-b166-e5b54a718ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 120)\n",
      "(708, 320)\n",
      "(708, 1024)\n",
      "(708, 1024)\n",
      "(708, 2048)\n",
      "(708, 2048)\n",
      "(708, 105)\n",
      "(708, 20)\n",
      "(708, 32)\n",
      "(708, 32)\n",
      "(708, 21)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "path = '/content/drive/MyDrive/Watashara_Projects/TIP/'\n",
    "\n",
    "\n",
    "# Load the data\n",
    "\n",
    "w2vec_all = pd.read_csv(path + 'features/word2vec_TIP_all.csv')\n",
    "esm2_all = pd.read_csv(path + 'features/Esm2_TIP_all.csv', header=None).iloc[:, :]\n",
    "prot_t5_bfd = pd.read_csv(path + 'features/TIP_al_prot_t5_xl_bfd.csv', header=None).iloc[1:, 1:]\n",
    "prot_t5_unief50 = pd.read_csv(path + 'features/TIP_all_prot_t5_xl_uniref50.csv', header=None).iloc[1:, 1:]\n",
    "reducedACID_all = pd.read_csv(path + 'features/reducedACID_all.csv', header=None).iloc[1:, 1:]\n",
    "reducedCHARGE_all = pd.read_csv(path + 'features/reducedCHARGE_all.csv', header=None).iloc[1:, 1:]\n",
    "AAC_all = pd.read_csv(path + 'features/AAC_all.csv', header=None).iloc[1:, 1:]\n",
    "PAAC_all = pd.read_csv(path + 'features/PAAC_all.csv', header=None).iloc[1:, 1:]\n",
    "\n",
    "BiGRU_all = pd.read_csv(path + 'features/BiGRU_all.csv', header=None).iloc[:, :]\n",
    "BiLSTM_all = pd.read_csv(path + 'features/BiLSTM_all.csv', header=None).iloc[:, :]\n",
    "\n",
    "# esm1_2_w2vec = np.column_stack((data_, esm2, esmv1))\n",
    "seq_feat = np.column_stack((reducedACID_all,reducedCHARGE_all, AAC_all, PAAC_all))\n",
    "data_np_all = np.array(seq_feat)\n",
    "\n",
    "seq_feat = np.column_stack((reducedACID_all,reducedCHARGE_all, AAC_all, PAAC_all))\n",
    "\n",
    "set1_feat = np.column_stack((seq_feat,esm2_all,prot_t5_bfd,prot_t5_unief50,w2vec_all))\n",
    "set2_feat = np.column_stack((w2vec_all,esm2_all,prot_t5_bfd,prot_t5_unief50,BiGRU_all, BiLSTM_all))\n",
    "set3_feat = np.column_stack((w2vec_all, seq_feat,esm2_all,prot_t5_bfd,prot_t5_unief50))\n",
    "# pd.DataFrame(set2_feat).to_csv('w2v_esm2_t5_bfd_unief50_BiGUR_BiLSTM.csv')\n",
    "print(np.shape(w2vec_all))\n",
    "print(np.shape(esm2_all))\n",
    "print(np.shape(prot_t5_bfd))\n",
    "print(np.shape(prot_t5_unief50))\n",
    "print(np.shape(BiGRU_all))\n",
    "print(np.shape(BiLSTM_all))\n",
    "print(np.shape(seq_feat))\n",
    "print(np.shape(AAC_all))\n",
    "print(np.shape(reducedCHARGE_all))\n",
    "print(np.shape(reducedACID_all))\n",
    "print(np.shape(PAAC_all)))\n",
    "\n",
    "set1 = np.array(set1_feat)\n",
    "set2 = np.array(set2_feat)\n",
    "set3 = np.array(set3_feat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NX0f1a70T97S"
   },
   "source": [
    "**LSTM_Selfattention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ndo5Zq9E1OyR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71404,
     "status": "ok",
     "timestamp": 1724491039354,
     "user": {
      "displayName": "Saeed Ahmed",
      "userId": "16724720564507897686"
     },
     "user_tz": -120
    },
    "id": "wNfAEuBDbqni",
    "outputId": "f1fd9857-d9e2-49a3-8409-db19603b5e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.6070 - loss: 0.7508 - val_accuracy: 0.6438 - val_loss: 0.6531 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7945 - loss: 0.4589 - val_accuracy: 0.6575 - val_loss: 0.6345 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8081 - loss: 0.4240 - val_accuracy: 0.6438 - val_loss: 0.6305 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8554 - loss: 0.3405 - val_accuracy: 0.6575 - val_loss: 0.6237 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8792 - loss: 0.3286 - val_accuracy: 0.6438 - val_loss: 0.6181 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8617 - loss: 0.3583 - val_accuracy: 0.6849 - val_loss: 0.6039 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8895 - loss: 0.2981 - val_accuracy: 0.6986 - val_loss: 0.5931 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8960 - loss: 0.2997 - val_accuracy: 0.7123 - val_loss: 0.5784 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8670 - loss: 0.3067 - val_accuracy: 0.7671 - val_loss: 0.5582 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9112 - loss: 0.2792 - val_accuracy: 0.7534 - val_loss: 0.5575 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9010 - loss: 0.2702 - val_accuracy: 0.8082 - val_loss: 0.5324 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8960 - loss: 0.2736 - val_accuracy: 0.8082 - val_loss: 0.5175 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8995 - loss: 0.2529 - val_accuracy: 0.8356 - val_loss: 0.5083 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8843 - loss: 0.2610 - val_accuracy: 0.8356 - val_loss: 0.4894 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9004 - loss: 0.2772 - val_accuracy: 0.8082 - val_loss: 0.4731 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9189 - loss: 0.2387 - val_accuracy: 0.8356 - val_loss: 0.4727 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9268 - loss: 0.2155 - val_accuracy: 0.8356 - val_loss: 0.4593 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9212 - loss: 0.2290 - val_accuracy: 0.8356 - val_loss: 0.4517 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9244 - loss: 0.2201 - val_accuracy: 0.8493 - val_loss: 0.4413 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9276 - loss: 0.2238 - val_accuracy: 0.8356 - val_loss: 0.4385 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9388 - loss: 0.1985 - val_accuracy: 0.8493 - val_loss: 0.4472 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9318 - loss: 0.2079 - val_accuracy: 0.8493 - val_loss: 0.4453 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9244 - loss: 0.2308 - val_accuracy: 0.8493 - val_loss: 0.4478 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9467 - loss: 0.1761 - val_accuracy: 0.8493 - val_loss: 0.4394 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9458 - loss: 0.1722 - val_accuracy: 0.8630 - val_loss: 0.4373 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9367 - loss: 0.1651 - val_accuracy: 0.8630 - val_loss: 0.4448 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9186 - loss: 0.2117 - val_accuracy: 0.8630 - val_loss: 0.4329 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9394 - loss: 0.1648 - val_accuracy: 0.8630 - val_loss: 0.4439 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9354 - loss: 0.1750 - val_accuracy: 0.8630 - val_loss: 0.4389 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9353 - loss: 0.1691 - val_accuracy: 0.8630 - val_loss: 0.4441 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9484 - loss: 0.1483 - val_accuracy: 0.8630 - val_loss: 0.4649 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9402 - loss: 0.1716 - val_accuracy: 0.8630 - val_loss: 0.4804 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9429 - loss: 0.1598 - val_accuracy: 0.8630 - val_loss: 0.4786 - learning_rate: 2.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9508 - loss: 0.1520 - val_accuracy: 0.8630 - val_loss: 0.4785 - learning_rate: 2.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9460 - loss: 0.1690 - val_accuracy: 0.8630 - val_loss: 0.4766 - learning_rate: 2.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9415 - loss: 0.1468 - val_accuracy: 0.8630 - val_loss: 0.4841 - learning_rate: 2.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9412 - loss: 0.1531 - val_accuracy: 0.8630 - val_loss: 0.4863 - learning_rate: 2.0000e-04\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9246 - loss: 0.2107 - val_accuracy: 0.8630 - val_loss: 0.4358 - learning_rate: 4.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9147 - loss: 0.2381 - val_accuracy: 0.8630 - val_loss: 0.4399 - learning_rate: 4.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9151 - loss: 0.2308 - val_accuracy: 0.8630 - val_loss: 0.4427 - learning_rate: 4.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9128 - loss: 0.2532 - val_accuracy: 0.8630 - val_loss: 0.4466 - learning_rate: 4.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9368 - loss: 0.1972 - val_accuracy: 0.8630 - val_loss: 0.4484 - learning_rate: 4.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9394 - loss: 0.1994 - val_accuracy: 0.8630 - val_loss: 0.4514 - learning_rate: 4.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9280 - loss: 0.1824 - val_accuracy: 0.8630 - val_loss: 0.4525 - learning_rate: 8.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9470 - loss: 0.1665 - val_accuracy: 0.8630 - val_loss: 0.4539 - learning_rate: 8.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9380 - loss: 0.1922 - val_accuracy: 0.8630 - val_loss: 0.4549 - learning_rate: 8.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9438 - loss: 0.1865 - val_accuracy: 0.8630 - val_loss: 0.4557 - learning_rate: 8.0000e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9416 - loss: 0.1679 - val_accuracy: 0.8630 - val_loss: 0.4389 - learning_rate: 8.0000e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9359 - loss: 0.1770 - val_accuracy: 0.8630 - val_loss: 0.4423 - learning_rate: 8.0000e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9231 - loss: 0.2159 - val_accuracy: 0.8630 - val_loss: 0.4453 - learning_rate: 8.0000e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9206 - loss: 0.2262 - val_accuracy: 0.8630 - val_loss: 0.4484 - learning_rate: 8.0000e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9127 - loss: 0.2177 - val_accuracy: 0.8630 - val_loss: 0.4504 - learning_rate: 8.0000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9353 - loss: 0.1718 - val_accuracy: 0.8630 - val_loss: 0.4521 - learning_rate: 8.0000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9218 - loss: 0.1910 - val_accuracy: 0.8630 - val_loss: 0.4536 - learning_rate: 1.6000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9520 - loss: 0.1775 - val_accuracy: 0.8630 - val_loss: 0.4554 - learning_rate: 1.6000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9401 - loss: 0.1654 - val_accuracy: 0.8630 - val_loss: 0.4565 - learning_rate: 1.6000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9431 - loss: 0.1686 - val_accuracy: 0.8630 - val_loss: 0.4585 - learning_rate: 1.6000e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9390 - loss: 0.2086 - val_accuracy: 0.8630 - val_loss: 0.4418 - learning_rate: 1.6000e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9275 - loss: 0.2140 - val_accuracy: 0.8630 - val_loss: 0.4442 - learning_rate: 1.6000e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9104 - loss: 0.2339 - val_accuracy: 0.8630 - val_loss: 0.4474 - learning_rate: 1.6000e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9389 - loss: 0.1658 - val_accuracy: 0.8630 - val_loss: 0.4495 - learning_rate: 1.6000e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9259 - loss: 0.2022 - val_accuracy: 0.8630 - val_loss: 0.4514 - learning_rate: 1.6000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.1735 - val_accuracy: 0.8630 - val_loss: 0.4532 - learning_rate: 1.6000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9330 - loss: 0.2038 - val_accuracy: 0.8630 - val_loss: 0.4542 - learning_rate: 1.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9441 - loss: 0.1637 - val_accuracy: 0.8630 - val_loss: 0.4543 - learning_rate: 1.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9208 - loss: 0.2203 - val_accuracy: 0.8630 - val_loss: 0.4554 - learning_rate: 1.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9136 - loss: 0.2016 - val_accuracy: 0.8630 - val_loss: 0.4559 - learning_rate: 1.0000e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9388 - loss: 0.1696 - val_accuracy: 0.8630 - val_loss: 0.4443 - learning_rate: 1.0000e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9350 - loss: 0.2094 - val_accuracy: 0.8630 - val_loss: 0.4473 - learning_rate: 1.0000e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9322 - loss: 0.1933 - val_accuracy: 0.8630 - val_loss: 0.4491 - learning_rate: 1.0000e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9488 - loss: 0.1815 - val_accuracy: 0.8630 - val_loss: 0.4505 - learning_rate: 1.0000e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9392 - loss: 0.1965 - val_accuracy: 0.8630 - val_loss: 0.4522 - learning_rate: 1.0000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9319 - loss: 0.1847 - val_accuracy: 0.8630 - val_loss: 0.4536 - learning_rate: 1.0000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9236 - loss: 0.1934 - val_accuracy: 0.8630 - val_loss: 0.4545 - learning_rate: 1.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9336 - loss: 0.1984 - val_accuracy: 0.8630 - val_loss: 0.4564 - learning_rate: 1.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9203 - loss: 0.2059 - val_accuracy: 0.8630 - val_loss: 0.4577 - learning_rate: 1.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9073 - loss: 0.2278 - val_accuracy: 0.8630 - val_loss: 0.4589 - learning_rate: 1.0000e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9166 - loss: 0.2283 - val_accuracy: 0.8630 - val_loss: 0.4466 - learning_rate: 1.0000e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9317 - loss: 0.1897 - val_accuracy: 0.8630 - val_loss: 0.4480 - learning_rate: 1.0000e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9461 - loss: 0.2027 - val_accuracy: 0.8630 - val_loss: 0.4498 - learning_rate: 1.0000e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9106 - loss: 0.2083 - val_accuracy: 0.8630 - val_loss: 0.4507 - learning_rate: 1.0000e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9195 - loss: 0.2202 - val_accuracy: 0.8630 - val_loss: 0.4519 - learning_rate: 1.0000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9206 - loss: 0.2042 - val_accuracy: 0.8630 - val_loss: 0.4533 - learning_rate: 1.0000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9398 - loss: 0.1999 - val_accuracy: 0.8630 - val_loss: 0.4538 - learning_rate: 1.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9236 - loss: 0.2130 - val_accuracy: 0.8630 - val_loss: 0.4538 - learning_rate: 1.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9294 - loss: 0.2121 - val_accuracy: 0.8630 - val_loss: 0.4545 - learning_rate: 1.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9239 - loss: 0.2101 - val_accuracy: 0.8630 - val_loss: 0.4551 - learning_rate: 1.0000e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9139 - loss: 0.2044 - val_accuracy: 0.8630 - val_loss: 0.4485 - learning_rate: 1.0000e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9258 - loss: 0.2160 - val_accuracy: 0.8630 - val_loss: 0.4505 - learning_rate: 1.0000e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9176 - loss: 0.2001 - val_accuracy: 0.8630 - val_loss: 0.4516 - learning_rate: 1.0000e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9429 - loss: 0.1911 - val_accuracy: 0.8630 - val_loss: 0.4544 - learning_rate: 1.0000e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9266 - loss: 0.1973 - val_accuracy: 0.8630 - val_loss: 0.4568 - learning_rate: 1.0000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9372 - loss: 0.1797 - val_accuracy: 0.8630 - val_loss: 0.4574 - learning_rate: 1.0000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9149 - loss: 0.1924 - val_accuracy: 0.8630 - val_loss: 0.4580 - learning_rate: 1.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9267 - loss: 0.1861 - val_accuracy: 0.8630 - val_loss: 0.4593 - learning_rate: 1.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9474 - loss: 0.1660 - val_accuracy: 0.8630 - val_loss: 0.4597 - learning_rate: 1.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9287 - loss: 0.2114 - val_accuracy: 0.8630 - val_loss: 0.4603 - learning_rate: 1.0000e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9432 - loss: 0.1874 - val_accuracy: 0.8630 - val_loss: 0.4497 - learning_rate: 1.0000e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9422 - loss: 0.1888 - val_accuracy: 0.8630 - val_loss: 0.4516 - learning_rate: 1.0000e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9238 - loss: 0.2170 - val_accuracy: 0.8630 - val_loss: 0.4531 - learning_rate: 1.0000e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9310 - loss: 0.1999 - val_accuracy: 0.8630 - val_loss: 0.4530 - learning_rate: 1.0000e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9203 - loss: 0.2046 - val_accuracy: 0.8630 - val_loss: 0.4541 - learning_rate: 1.0000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9291 - loss: 0.2157 - val_accuracy: 0.8630 - val_loss: 0.4552 - learning_rate: 1.0000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9122 - loss: 0.2746 - val_accuracy: 0.8630 - val_loss: 0.4567 - learning_rate: 1.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9264 - loss: 0.1692 - val_accuracy: 0.8630 - val_loss: 0.4578 - learning_rate: 1.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9316 - loss: 0.1878 - val_accuracy: 0.8630 - val_loss: 0.4584 - learning_rate: 1.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9258 - loss: 0.2238 - val_accuracy: 0.8630 - val_loss: 0.4591 - learning_rate: 1.0000e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9414 - loss: 0.1774 - val_accuracy: 0.8767 - val_loss: 0.3645 - learning_rate: 1.0000e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9416 - loss: 0.2036 - val_accuracy: 0.8767 - val_loss: 0.3662 - learning_rate: 1.0000e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9309 - loss: 0.2045 - val_accuracy: 0.8767 - val_loss: 0.3677 - learning_rate: 1.0000e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9169 - loss: 0.2331 - val_accuracy: 0.8767 - val_loss: 0.3684 - learning_rate: 1.0000e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9234 - loss: 0.2181 - val_accuracy: 0.8767 - val_loss: 0.3692 - learning_rate: 1.0000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9295 - loss: 0.2097 - val_accuracy: 0.8767 - val_loss: 0.3696 - learning_rate: 1.0000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9250 - loss: 0.1912 - val_accuracy: 0.8767 - val_loss: 0.3704 - learning_rate: 1.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9286 - loss: 0.1899 - val_accuracy: 0.8767 - val_loss: 0.3705 - learning_rate: 1.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9317 - loss: 0.2065 - val_accuracy: 0.8767 - val_loss: 0.3704 - learning_rate: 1.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9228 - loss: 0.2035 - val_accuracy: 0.8767 - val_loss: 0.3709 - learning_rate: 1.0000e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9370 - loss: 0.2234 - val_accuracy: 0.8767 - val_loss: 0.3709 - learning_rate: 1.0000e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9163 - loss: 0.2083 - val_accuracy: 0.9589 - val_loss: 0.2136 - learning_rate: 1.0000e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9255 - loss: 0.2189 - val_accuracy: 0.9726 - val_loss: 0.2141 - learning_rate: 1.0000e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9307 - loss: 0.2107 - val_accuracy: 0.9726 - val_loss: 0.2143 - learning_rate: 1.0000e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9361 - loss: 0.1709 - val_accuracy: 0.9726 - val_loss: 0.2141 - learning_rate: 1.0000e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9301 - loss: 0.1780 - val_accuracy: 0.9726 - val_loss: 0.2145 - learning_rate: 1.0000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9509 - loss: 0.1627 - val_accuracy: 0.9726 - val_loss: 0.2145 - learning_rate: 1.0000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9356 - loss: 0.1792 - val_accuracy: 0.9726 - val_loss: 0.2151 - learning_rate: 1.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9172 - loss: 0.2419 - val_accuracy: 0.9726 - val_loss: 0.2149 - learning_rate: 1.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9476 - loss: 0.1843 - val_accuracy: 0.9726 - val_loss: 0.2153 - learning_rate: 1.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9334 - loss: 0.1905 - val_accuracy: 0.9726 - val_loss: 0.2152 - learning_rate: 1.0000e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9336 - loss: 0.1899 - val_accuracy: 0.9726 - val_loss: 0.2158 - learning_rate: 1.0000e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.layers import BatchNormalization\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dropout, BatchNormalization, Flatten, Dense, Bidirectional\n",
    "import os\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, attention_width=50, attention_type=2, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "        self.attention_width = attention_width\n",
    "        self.attention_type = attention_type\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Ensure that input_shape[-1] (features) is correct\n",
    "        feature_dim = input_shape[-1]\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(feature_dim, self.attention_width),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(self.attention_width,),\n",
    "                                 initializer=\"zeros\", trainable=True)\n",
    "        self.u = self.add_weight(name=\"att_u\", shape=(self.attention_width,),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Ensure inputs are reshaped properly\n",
    "        v = tf.nn.tanh(tf.matmul(inputs, self.W) + self.b)\n",
    "        vu = tf.matmul(v, tf.expand_dims(self.u, -1))\n",
    "        alphas = tf.nn.softmax(tf.squeeze(vu, -1), axis=1)\n",
    "        alphas = tf.expand_dims(alphas, -1)\n",
    "        output = tf.reduce_sum(inputs * alphas, axis=1)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(SelfAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"attention_width\": self.attention_width,\n",
    "            \"attention_type\": self.attention_type,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "# Update the model architecture\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(132, return_sequences=True, recurrent_dropout=0.2))) # Add recurrent dropout\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(32, return_sequences=True, recurrent_dropout=0.2))  # Add recurrent dropout\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())  # Add Batch Normalization\n",
    "model.add(SelfAttention(attention_width=50, attention_type=2))  # Use SelfAttention layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# def get_CNN_model(input_dim, out_dim):\n",
    "#     model.add(Dense(int(input_dim / 2), activation='gelu', kernel_regularizer='l2'))  # Add L2 regularization\n",
    "#     model.add(Dense(out_dim, activation='relu', name=\"Dense_2\"))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid', name=\"Dense_2\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Introduce callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "path = '/content/drive/MyDrive/Watashara_Projects/TIP/'\n",
    "\n",
    "# data_ = pd.read_csv(path + 'BiGRU_all.csv',header=None)\n",
    "data = np.array(PAAC_all)\n",
    "label1 = np.ones((int(206), 1))\n",
    "label2 = np.zeros((int(502), 1))\n",
    "label = np.append(label1, label2)\n",
    "scale_data = scale(data[:,:])\n",
    "\n",
    "folder= 'PAAC_set2'\n",
    "# Define the directory to save the best models\n",
    "model_save_dir = path + f'Results/{folder}/Models/'\n",
    "# Ensure the save directory exists\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(scale_data, label)\n",
    "\n",
    "# # y = labels\n",
    "X_train, X_ind, y_train, y_ind = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert numpy arrays to DataFrames\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_ind_df = pd.DataFrame(X_ind)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_ind_df = pd.DataFrame(y_ind)\n",
    "\n",
    "# Save the training and test data\n",
    "X_train_data = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "X_train_data.to_csv(path+f'Results/{folder}/XtrainData.csv', index=False)\n",
    "\n",
    "X_test_data = pd.concat([X_ind_df, y_ind_df], axis=1)\n",
    "X_test_data.to_csv(path+f'Results/{folder}/XtestData.csv', index=False)\n",
    "\n",
    "\n",
    "# train_all_feat = pd.read_csv(path + 'Lasso_XtrainData.csv')\n",
    "\n",
    "# X_train = train_all_feat.iloc[:, :-1].values\n",
    "# y_train = train_all_feat.iloc[:, -1].values\n",
    "\n",
    "y = y_train\n",
    "X = np.reshape(X_train, (-1, 1, X_train.shape[1]))\n",
    "\n",
    "sepscores = []\n",
    "ytest = np.ones((1, 2)) * 0.5\n",
    "yscore = np.ones((1, 2)) * 0.5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "for fold, (train, test) in enumerate(skf.split(X, y_train)):\n",
    "    y_train = to_categorical(y[train])\n",
    "    cv_clf = model\n",
    "    # Model checkpoint to save the best model for each fold\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        model_save_dir + f'best_model_fold_{fold + 1}.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='auto')\n",
    "    hist = cv_clf.fit(X[train],\n",
    "                      y_train,\n",
    "                      epochs=50,  # Increase the number of epochs\n",
    "                      validation_split=0.1,  # Use part of the training data for validation\n",
    "                      callbacks=[early_stopping, reduce_lr, model_checkpoint])  # Use callbacks, model_checkpoint\n",
    "\n",
    "    y_score = cv_clf.predict(X[test])\n",
    "    y_class = categorical_probas_to_classes(y_score)\n",
    "\n",
    "    y_test = to_categorical(y[test])\n",
    "    ytest = np.vstack((ytest, y_test))\n",
    "    y_test_tmp = y[test]\n",
    "    yscore = np.vstack((yscore, y_score))\n",
    "\n",
    "    acc, sensitivity, specificity, mcc, f1, aupr = calculate_performance(\n",
    "        len(y_class), y_class, y_test_tmp, pred_probas=y_score[:, 1]\n",
    "    )\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test[:, 1], y_score[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    precision, recall, _ = precision_recall_curve(y_test[:, 1], y_score[:, 1])\n",
    "    pr_auc = auc(recall, precision)\n",
    "    sepscores.append([acc, sensitivity, specificity, mcc, f1, roc_auc, pr_auc])\n",
    "\n",
    "scores = np.array(sepscores)\n",
    "result1 = np.mean(scores, axis=0)\n",
    "H1 = result1.tolist()\n",
    "sepscores.append(H1)\n",
    "result = sepscores\n",
    "\n",
    "row = yscore.shape[0]\n",
    "yscore = yscore[np.array(range(1, row)), :]\n",
    "yscore_sum = pd.DataFrame(data=yscore)\n",
    "yscore_sum.to_csv(path + f'Results/{folder}/Set2_yscore.csv')\n",
    "\n",
    "ytest = ytest[np.array(range(1, row)), :]\n",
    "ytest_sum = pd.DataFrame(data=ytest)\n",
    "ytest_sum.to_csv(path + f'Results/{folder}/Set2_ytest.csv')\n",
    "\n",
    "data_csv = pd.DataFrame(data=result)\n",
    "data_csv.to_csv(path + f'Results/{folder}/Set2_CV.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsXInIC0-J-u"
   },
   "source": [
    "**CNN-LSTM-SelfAttention indpendent test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18009,
     "status": "ok",
     "timestamp": 1724491368092,
     "user": {
      "displayName": "Saeed Ahmed",
      "userId": "16724720564507897686"
     },
     "user_tz": -120
    },
    "id": "tB9FVW1nKpVb",
    "outputId": "e371e9af-7acb-49fb-d4ca-205fd889b1fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /content/drive/MyDrive/Watashara_Projects/TIP/Results/PAAC_set2/Models/best_model_fold_1.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step\n",
      "Results for best_model_fold_1.keras:\n",
      "Accuracy: 0.8606965174129353\n",
      "Sensitivity: 0.8478260777410209\n",
      "Specificity: 0.8715596250315631\n",
      "MCC: 0.7193857199123069\n",
      "F1: 0.8478260823487713\n",
      "pr_auc: 0.8650192245530147\n",
      "AUC: 1.0\n",
      "Loaded model from /content/drive/MyDrive/Watashara_Projects/TIP/Results/PAAC_set2/Models/best_model_fold_2.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n",
      "Results for best_model_fold_2.keras:\n",
      "Accuracy: 0.8656716417910447\n",
      "Sensitivity: 0.8478260777410209\n",
      "Specificity: 0.8807339368740006\n",
      "MCC: 0.7292147866045113\n",
      "F1: 0.8524590117351967\n",
      "pr_auc: 0.8656815779301517\n",
      "AUC: 0.9998001998001999\n",
      "Loaded model from /content/drive/MyDrive/Watashara_Projects/TIP/Results/PAAC_set2/Models/best_model_fold_3.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n",
      "Results for best_model_fold_3.keras:\n",
      "Accuracy: 0.8656716417910447\n",
      "Sensitivity: 0.8478260777410209\n",
      "Specificity: 0.8807339368740006\n",
      "MCC: 0.7292147866045113\n",
      "F1: 0.8524590117351967\n",
      "pr_auc: 0.8663584665193922\n",
      "AUC: 0.9998001998001999\n",
      "Loaded model from /content/drive/MyDrive/Watashara_Projects/TIP/Results/PAAC_set2/Models/best_model_fold_4.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n",
      "Results for best_model_fold_4.keras:\n",
      "Accuracy: 0.8656716417910447\n",
      "Sensitivity: 0.8478260777410209\n",
      "Specificity: 0.8807339368740006\n",
      "MCC: 0.7292147866045113\n",
      "F1: 0.8524590117351967\n",
      "pr_auc: 0.8658381939613478\n",
      "AUC: 0.9998001998001999\n",
      "Loaded model from /content/drive/MyDrive/Watashara_Projects/TIP/Results/PAAC_set2/Models/best_model_fold_5.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step\n",
      "Results for best_model_fold_5.keras:\n",
      "Accuracy: 0.8656716417910447\n",
      "Sensitivity: 0.8478260777410209\n",
      "Specificity: 0.8807339368740006\n",
      "MCC: 0.7292147866045113\n",
      "F1: 0.8524590117351967\n",
      "pr_auc: 0.8664015548406409\n",
      "AUC: 0.9998001998001999\n",
      "Loaded model from /content/drive/MyDrive/Watashara_Projects/TIP/Results/PAAC_set2/Models/best_model_fold_6.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step\n",
      "Results for best_model_fold_6.keras:\n",
      "Accuracy: 0.8656716417910447\n",
      "Sensitivity: 0.8478260777410209\n",
      "Specificity: 0.8807339368740006\n",
      "MCC: 0.7292147866045113\n",
      "F1: 0.8524590117351967\n",
      "pr_auc: 0.8664006071338385\n",
      "AUC: 0.9998001998001999\n",
      "Loaded model from /content/drive/MyDrive/Watashara_Projects/TIP/Results/PAAC_set2/Models/best_model_fold_7.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step\n",
      "Results for best_model_fold_7.keras:\n",
      "Accuracy: 0.8656716417910447\n",
      "Sensitivity: 0.8478260777410209\n",
      "Specificity: 0.8807339368740006\n",
      "MCC: 0.7292147866045113\n",
      "F1: 0.8524590117351967\n",
      "pr_auc: 0.8665589013943805\n",
      "AUC: 0.9998001998001999\n",
      "Loaded model from /content/drive/MyDrive/Watashara_Projects/TIP/Results/PAAC_set2/Models/best_model_fold_8.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n",
      "Results for best_model_fold_8.keras:\n",
      "Accuracy: 0.8606965174129353\n",
      "Sensitivity: 0.8369565126417771\n",
      "Specificity: 0.8807339368740006\n",
      "MCC: 0.719054147921817\n",
      "F1: 0.8461538415046492\n",
      "pr_auc: 0.8655442906458604\n",
      "AUC: 0.9998998998998999\n",
      "Loaded model from /content/drive/MyDrive/Watashara_Projects/TIP/Results/PAAC_set2/Models/best_model_fold_9.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step\n",
      "Results for best_model_fold_9.keras:\n",
      "Accuracy: 0.8656716417910447\n",
      "Sensitivity: 0.8478260777410209\n",
      "Specificity: 0.8807339368740006\n",
      "MCC: 0.7292147866045113\n",
      "F1: 0.8524590117351967\n",
      "pr_auc: 0.8666229623584144\n",
      "AUC: 0.9998001998001999\n",
      "Loaded model from /content/drive/MyDrive/Watashara_Projects/TIP/Results/PAAC_set2/Models/best_model_fold_10.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step\n",
      "Results for best_model_fold_10.keras:\n",
      "Accuracy: 0.8656716417910447\n",
      "Sensitivity: 0.8478260777410209\n",
      "Specificity: 0.8807339368740006\n",
      "MCC: 0.7292147866045113\n",
      "F1: 0.8524590117351967\n",
      "pr_auc: 0.866557682239701\n",
      "AUC: 0.9998001998001999\n",
      "Results and predictions saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "\n",
    "# test_all_feat = pd.read_csv(path + 'Results/EN_set2/Lasso_XtestData.csv')\n",
    "\n",
    "# X_ind = test_all_feat.iloc[:, :-1].values\n",
    "# y_ind = test_all_feat.iloc[:, -1].values\n",
    "\n",
    "# Define the directory where the models are saved\n",
    "model_save_dir = f'/content/drive/MyDrive/Watashara_Projects/TIP/Results/{folder}/Models/'\n",
    "\n",
    "# List of model filenames\n",
    "model_files = [f'best_model_fold_{i + 1}.keras' for i in range(10)]\n",
    "\n",
    "# Initialize lists to store metrics and predictions\n",
    "all_metrics = []\n",
    "fold_metrics = []\n",
    "y_score_all_folds = []\n",
    "y_test_all_folds = []\n",
    "\n",
    "# Load the models with custom objects\n",
    "for model_file in model_files:\n",
    "    file_path = os.path.join(model_save_dir, model_file)\n",
    "\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"Model file not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        model = load_model(file_path, custom_objects={'SelfAttention': SelfAttention})\n",
    "        print(f\"Loaded model from {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model from {file_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Assuming X_ind and y_ind are your independent test data and labels\n",
    "    X_ind_reshaped = np.reshape(X_ind, (-1, 1, X_ind.shape[1]))\n",
    "    y_ind_categorical = to_categorical(y_ind)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_score = model.predict(X_ind_reshaped)\n",
    "    y_class = categorical_probas_to_classes(y_score)\n",
    "\n",
    "    # Save the predicted scores (y_score) and actual test labels (y_ind)\n",
    "    y_score_all_folds.append(y_score)\n",
    "    y_test_all_folds.append(y_ind)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    acc, sensitivity, specificity, mcc, f1, aupr = calculate_performance(\n",
    "        len(y_ind), y_class, y_ind, pred_probas=y_score[:, 1]\n",
    "    )\n",
    "    fpr, tpr, _ = roc_curve(y_class, y_score[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    precision, recall, _ = precision_recall_curve(y_ind, y_score[:, 1])\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    metrics = {\n",
    "        'Model': model_file,\n",
    "        'Accuracy': acc,\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity,\n",
    "        'MCC': mcc,\n",
    "        'F1': f1,\n",
    "        'AUC': roc_auc,\n",
    "        'AUPR': pr_auc\n",
    "    }\n",
    "\n",
    "    fold_metrics.append(metrics)\n",
    "\n",
    "    print(f\"Results for {model_file}:\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Sensitivity: {sensitivity}\")\n",
    "    print(f\"Specificity: {specificity}\")\n",
    "    print(f\"MCC: {mcc}\")\n",
    "    print(f\"F1: {f1}\")\n",
    "    print(f\"pr_auc: {pr_auc}\")\n",
    "    print(f\"AUC: {roc_auc}\")\n",
    "\n",
    "# Convert fold metrics to DataFrame and save to CSV\n",
    "fold_metrics_df = pd.DataFrame(fold_metrics)\n",
    "fold_metrics_df.to_csv(os.path.join(model_save_dir, 'Fold_Metrics.csv'), index=False)\n",
    "\n",
    "# Save the predicted scores and actual test labels to CSV\n",
    "# Flatten y_score and y_test to ensure they are saved correctly\n",
    "y_score_flat = np.concatenate(y_score_all_folds, axis=0)\n",
    "y_test_flat = np.concatenate(y_test_all_folds, axis=0)\n",
    "\n",
    "# Convert to DataFrames\n",
    "y_score_df = pd.DataFrame(y_score_flat, columns=[f'Class_{i}' for i in range(y_score_flat.shape[1])])\n",
    "y_test_df = pd.DataFrame(y_test_flat, columns=['True_Label'])\n",
    "\n",
    "# Save to CSV\n",
    "y_score_df.to_csv(os.path.join(model_save_dir, 'y_score_all_folds.csv'), index=False)\n",
    "y_test_df.to_csv(os.path.join(model_save_dir, 'y_test_all_folds.csv'), index=False)\n",
    "\n",
    "# Average the metrics across all folds (excluding non-numeric columns)\n",
    "numeric_metrics_df = fold_metrics_df.drop(columns=['Model'])\n",
    "mean_metrics = numeric_metrics_df.mean()\n",
    "mean_metrics_df = pd.DataFrame([mean_metrics], columns=mean_metrics.index)\n",
    "mean_metrics_df.to_csv(os.path.join(model_save_dir, 'Average_Metrics.csv'), index=False)\n",
    "\n",
    "print(\"Results and predictions saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNN8SCxtwDdU"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "path = '/content/drive/MyDrive/Watashara_Projects/TIP/'\n",
    "# Define the directory to save the best models\n",
    "\n",
    "\n",
    "data_ = pd.read_csv(path + 'update_LASSO_selected_feature_values_SET2.csv')\n",
    "data = np.array(data_)\n",
    "label1 = np.ones((int(206), 1))\n",
    "label2 = np.zeros((int(502), 1))\n",
    "label = np.append(label1, label2)\n",
    "scale_data = scale(data[:,:])\n",
    "\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(scale_data, label)\n",
    "\n",
    "# # y = labels\n",
    "X_train, X_ind, y_train, y_ind = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert numpy arrays to DataFrames\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_ind_df = pd.DataFrame(X_ind)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_ind_df = pd.DataFrame(y_ind)\n",
    "\n",
    "# Save the training and test data\n",
    "X_train_data = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "X_train_data.to_csv(path + '1_XtrainData.csv', index=False)\n",
    "\n",
    "X_test_data = pd.concat([X_ind_df, y_ind_df], axis=1)\n",
    "X_test_data.to_csv(path + '1_XtestData.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM6N5fbXA+FfSuTP0dIjUS/",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
